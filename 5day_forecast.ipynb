{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code (will be) set up to generate a forecasted impact map of a specified area.\n",
    "The area in the example case is Houston, TX\n",
    "The inundation extent is sourced from the National Water Model forecast. \n",
    "Depth model is calculated from the inundation extent and the national 3m DEM\n",
    "The impact map is calculated from the depth and the CDC SVI scores at the census tract scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit code so that it runs automatically every hour\n",
    "# use python.12.4 kernel\n",
    "# THIS IS A WORK IN PROGRESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the dependencies require numpy <2, so make sure your numpy package matches that requirement. If it does, skip the next two steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import arcpy\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and set the paths to the working directory and input files\n",
    "TO DO: \n",
    "1. Replace the directory path with the path to the folder you want to work in\n",
    "2. Replace dem_name with path to the dem you want to use (as a tif) \n",
    "3. Replace the inund_polygon with path to the area extent you want to map (as a .shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New folder created at: C:/Users/Lyn/Documents/ArcGIS/CUAHSI_SI_2024/07122024_5day\\5dayforecast_07092024\n",
      "Current Working Directory:  C:\\Users\\Lyn\\Documents\\ArcGIS\\CUAHSI_SI_2024\\07122024_5day\\5dayforecast_07092024\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import arcpy\n",
    "from datetime import datetime\n",
    "\n",
    "# Format the current datetime as a string in the desired format (e.g., YYYYMMDD_HHMMSS)\n",
    "datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "# Replace 'path/to/your/directory' with the path to your desired working directory\n",
    "directory = 'C:/Users/Lyn/Documents/ArcGIS/CUAHSI_SI_2024/07122024_5day'\n",
    "\n",
    "\n",
    "# Create a new folder within the current working directory\n",
    "resultfolder = \"5dayforecast_07092024\"\n",
    "os.makedirs(os.path.join(directory, resultfolder), exist_ok=True)\n",
    "print(f\"New folder created at: {os.path.join(directory, resultfolder)}\")\n",
    "infolder = directory +'/'+ resultfolder + '/'\n",
    "\n",
    "\n",
    "# set up input variables\n",
    "dem_name = 'C:/Users/Lyn/Documents/Programming/Python_codes/fwdet/Forecast_test_5day/Houston_DEM.tif'\n",
    "extent = 'C:/Users/Lyn/Documents/ArcGIS/CUAHSI_SI_2024/Houston_huc.shp'\n",
    "svi = 'C:/Users/Lyn/Documents/Programming/Python_codes/Impact_Map_Forecasting/Texas_example/aligned_svi_raster.tif'\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(infolder)\n",
    "# Verify the current working directory\n",
    "print(\"Current Working Directory: \", os.getcwd())\n",
    "\n",
    "# set up input and output variables\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# make a geodatabase within the infolder   \n",
    "gdb_path = infolder \n",
    "# Create the geodatabase\n",
    "arcpy.CreateFileGDB_management(out_folder_path = infolder, out_name='geodatabase.gdb')\n",
    "#workspace\n",
    "ws = arcpy.env.workspace = infolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geopandas rasterio shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the NWM 5 day inundation exent. This section will download it as a shapefile, merge polygons, and prepare for depth calculaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            geometry feature_id  \\\n",
      "0  MULTIPOLYGON (((-99.06275 27.50207, -99.06276 ...     322529   \n",
      "1  MULTIPOLYGON (((-99.10026 27.52774, -99.10016 ...     322547   \n",
      "2  POLYGON ((-99.09559 27.52107, -99.09568 27.520...     322547   \n",
      "3  MULTIPOLYGON (((-99.0996 27.50099, -99.09949 2...     322547   \n",
      "4  MULTIPOLYGON (((-99.07352 27.50175, -99.07342 ...     322551   \n",
      "\n",
      "   streamflow_cfs           reference_time              update_time  oid  \n",
      "0           24.37  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    1  \n",
      "1            4.94  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    2  \n",
      "2            4.94  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    3  \n",
      "3            4.94  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    4  \n",
      "4           21.90  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    5  \n",
      "                                            geometry feature_id  \\\n",
      "0  MULTIPOLYGON (((-99.06275 27.50207, -99.06276 ...     322529   \n",
      "1  MULTIPOLYGON (((-99.10026 27.52774, -99.10016 ...     322547   \n",
      "2  POLYGON ((-99.09559 27.52107, -99.09568 27.520...     322547   \n",
      "3  MULTIPOLYGON (((-99.0996 27.50099, -99.09949 2...     322547   \n",
      "4  MULTIPOLYGON (((-99.07352 27.50175, -99.07342 ...     322551   \n",
      "\n",
      "   streamflow_cfs           reference_time              update_time  oid  \n",
      "0           24.37  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    1  \n",
      "1            4.94  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    2  \n",
      "2            4.94  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    3  \n",
      "3            4.94  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    4  \n",
      "4           21.90  2024-07-12 12:00:00 UTC  2024-07-12 18:30:32 UTC    5  \n"
     ]
    }
   ],
   "source": [
    "# query the NOAA API for the most recent flood predictions\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "\n",
    "# Construct the query URL\n",
    "# To change the query, you can go to https://maps.water.noaa.gov/server/rest/services/nwm\n",
    "# Then select the link you want, copy it here, and add /0/query to the end\n",
    "# e.g. https://link_to_service/0/query\n",
    "query_url = \"https://maps.water.noaa.gov/server/rest/services/nwm/mrf_gfs_5day_max_inundation_extent/MapServer/0/query\"\n",
    "params = {\n",
    "    'where': '1=1',\n",
    "    'outFields': '*',\n",
    "    'outSR': '4326',  # Specify output spatial reference if needed\n",
    "    'f': 'geojson',  # Request geojson output\n",
    "    'returnGeometry': 'true'\n",
    "}\n",
    "# Make the request\n",
    "response = requests.get(query_url, params=params)\n",
    "\n",
    "\n",
    "# Check if the server is running correctly. A response of 500 means there is a server error. \n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        # Attempt to convert the response to a GeoDataFrame\n",
    "        predictions = gpd.GeoDataFrame.from_features(response.json(), crs=\"EPSG:4326\")\n",
    "        print(predictions.head())\n",
    "    except ValueError as e:\n",
    "        # Handle JSON decoding errors\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "else:\n",
    "    # The request failed; print the status code and response text\n",
    "    print(f\"Request failed with status {response.status_code}: {response.text}\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "predictions = gpd.GeoDataFrame.from_features(response.json(), crs=\"EPSG:4326\")\n",
    "print(predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   COUNT    SHAPE_Leng    SHAPE_Area  \\\n",
      "0  924.0  8.358015e+06  3.540893e+08   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((-10666025.504 3471520.993, -10...  \n"
     ]
    }
   ],
   "source": [
    "# To use if you already have a fim file that is cleaned up\n",
    "import geopandas as gpd\n",
    "\n",
    "# Specify the path to the shapefile\n",
    "shapefile_path = \"F:/SI_2024/5day_07182024_smooth.shp\"\n",
    "\n",
    "# Read the shapefile into a GeoDataFrame\n",
    "predictions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Print the GeoDataFrame\n",
    "print(predictions.head())\n",
    "\n",
    "# To change the CRS to WGS84 (EPSG:4326) as an example\n",
    "gdf = predictions.to_crs(epsg=4326)\n",
    "predictions = gdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip the predictions to the huc extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip predictions to huc extent\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# Replace 'path/to/your/shapefile.shp' with the actual path to your shapefile\n",
    "shapefile_path = extent\n",
    "huc = gpd.read_file(shapefile_path)\n",
    "\n",
    "# To change the CRS to WGS84 (EPSG:4326) as an example\n",
    "gdf = huc.to_crs(epsg=4326)\n",
    "huc = gdf\n",
    "# Now `gdf` is a GeoDataFrame containing the data from your shapefile\n",
    "\n",
    "# clip the predictions to the extent of interest - defined by the dem_name above\n",
    "\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Assuming `gdf_to_clip` is your GeoDataFrame that you want to clip,\n",
    "# and `clipping_polygon` is a GeoDataFrame containing the polygon to clip to.\n",
    "\n",
    "# Step 1: Ensure both GeoDataFrames are in the same CRS\n",
    "if predictions.crs != huc.crs:\n",
    "    gdf_to_clip = predictions.to_crs(huc.crs)\n",
    "else:\n",
    "    gdf_to_clip = predictions\n",
    "# Step 2: Use the clip function\n",
    "clipped_gdf = gpd.clip(gdf_to_clip, huc)\n",
    "\n",
    "# `clipped_gdf` now contains the geometries from `gdf_to_clip` clipped to the extent of `clipping_polygon`.\n",
    "predictions = clipped_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If predictions is empty, print a message and exit the script\n",
    "import sys\n",
    "if predictions.empty:\n",
    "    print(\"No flood predictions in this area found.\")\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the shapefiles a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissolve all polygons\n",
    "dissolved_gdf = predictions.dissolve()\n",
    "predictions = dissolved_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyn\\AppData\\Local\\Temp\\ipykernel_7140\\3429588930.py:5: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  dissolved_gdf.to_file(output_path)\n",
      "C:\\Users\\Lyn\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'streamflow_cfs' to 'streamflow'\n",
      "  ogr_write(\n",
      "C:\\Users\\Lyn\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'reference_time' to 'reference_'\n",
      "  ogr_write(\n",
      "C:\\Users\\Lyn\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'update_time' to 'update_tim'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "# Specify the path where you want to save the shapefile\n",
    "output_path = infolder + 'test.shp'\n",
    "\n",
    "# Export the dissolved GeoDataFrame as a shapefile\n",
    "dissolved_gdf.to_file(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FWDET2.1 calculates depth map from inundation extent\n",
    "### Written by Dr.Sagy Cohen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Invalid pointer ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 154\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# Removing created eronious generated objects\u001b[39;00m\n\u001b[0;32m    151\u001b[0m    \u001b[38;5;66;03m# arcpy.Delete_management(raster_polyline)\u001b[39;00m\n\u001b[0;32m    152\u001b[0m    \u001b[38;5;66;03m# arcpy.Delete_management(polyline)\u001b[39;00m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m boundary\n\u001b[1;32m--> 154\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[24], line 62\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m clip_dem_ras \u001b[38;5;241m=\u001b[39m arcpy\u001b[38;5;241m.\u001b[39mRaster(clip_dem)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Generate raster line. See CalculateBoundary docstring for more info\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m boundary \u001b[38;5;241m=\u001b[39m CalculateBoundary(dem, clip_dem_ras, inund_polygon, cell_size, numIterations, slopeTH)\n\u001b[0;32m     63\u001b[0m arcpy\u001b[38;5;241m.\u001b[39mAddMessage(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculated Boundary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#   arcpy.env.extent = arcpy.Extent(dem.extent.XMin, dem.extent.YMin, dem.extent.XMax, dem.extent.YMax)\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Convert boundary, i.e., raster line to int for cost allocation function. It only takes int rasters\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 118\u001b[0m, in \u001b[0;36mCalculateBoundary\u001b[1;34m(dem, clip_dem_ras, inund_polygon, cell_size, numIterations, slopeTH)\u001b[0m\n\u001b[0;32m    116\u001b[0m     arcpy\u001b[38;5;241m.\u001b[39mconversion\u001b[38;5;241m.\u001b[39mPolylineToRaster(polyline, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinerast15\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAXIMUM_LENGTH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNONE\u001b[39m\u001b[38;5;124m\"\u001b[39m, cell_size)\n\u001b[0;32m    117\u001b[0m raster_polyline \u001b[38;5;241m=\u001b[39m Raster(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinerast15\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 118\u001b[0m raster_polyline\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolyline.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# The input whose values will be used as the output cell values if the condition is false.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m inFalseConstant \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Invalid pointer "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate water depth from a flood extent polygon (e.g. from remote sensing analysis) based on\n",
    "an underlying DEM (or HAND).\n",
    "Program procedure:\n",
    "    1. Flood extent polygon to polyline\n",
    "    2. Polyline to Raster - DEM extent and resolution (Env)\n",
    "    3. Con - DEM values to Raster\n",
    "    4. Euclidean Allocation - assign boundary cell elevation to nearest domain cells\n",
    "    5. Calculate water depth by deducting DEM by Euclidean Allocation\n",
    "    6. Run low-pass Filter\n",
    "Created by Sagy Cohen, Surface Dynamics Modeling Lab, University of Alabama\n",
    "email: sagy.cohen@ua.edu\n",
    "web: http://sdml.ua.edu\n",
    "\n",
    "NOTE: the shapefile must be smaller than the dem extent\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "# Checkout the Spatial Analyst Toolkit\n",
    "arcpy.CheckOutExtension(['Spatial'])\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "def main():\n",
    "    ####################\n",
    "    #   INPUT/OUTPUT   #\n",
    "    ####################\n",
    "    # Inputs#\n",
    "    ws = arcpy.env.workspace = infolder\n",
    "    inund_polygon = output_path\n",
    "\n",
    "    clip_dem = '' #[Optional] - If empty, the clip_dem will be calculated with the Clip_management function\n",
    "    cost_raster ='' #[Optional] - If empty, the CostRaster will be calculated below\n",
    "\n",
    "    #Parameters#\n",
    "    numIterations = 10 #number of smoothing iterations\n",
    "    slopeTH = 0.5 #filtering slope threshold\n",
    "\n",
    "    #Output# water depth raster\n",
    "    Out_WaterDepth = 'WaterDepth'\n",
    "\n",
    "    # Create raster object from DEM\n",
    "    dem = arcpy.Raster(dem_name)\n",
    "    # Check if optional Cost Raster was provided\n",
    "    if not cost_raster:\n",
    "        cost_raster = (((dem <= 0)*999)+1)\n",
    "        cost_raster.save(ws + '\\CostRaster')\n",
    "\n",
    "    # Cell size here would be the x or y distance resolution from the raster\n",
    "    # i.e., a 30 meter dem would have a cell size of 30\n",
    "    cell_size = dem.meanCellHeight\n",
    "    # Proper string representation of dem extent to be accepted by Clip_management method\n",
    "    extent = '{} {} {} {}'.format(dem.extent.XMin, dem.extent.YMin, dem.extent.XMax, dem.extent.YMax)\n",
    "    \n",
    "    # If optional clip dem no provided then create a clipping dem cut out from the flood inundation polygon\n",
    "    if not clip_dem:\n",
    "        clip_dem = 'ClipDEM'\n",
    "        arcpy.management.Clip(dem, extent, clip_dem, inund_polygon, nodata_value= \"-9999\", clipping_geometry=\"ClippingGeometry\", maintain_clipping_extent=\"NO_MAINTAIN_EXTENT\")\n",
    "    clip_dem_ras = arcpy.Raster(clip_dem)\n",
    "    # Generate raster line. See CalculateBoundary docstring for more info\n",
    "    boundary = CalculateBoundary(dem, clip_dem_ras, inund_polygon, cell_size, numIterations, slopeTH)\n",
    "    arcpy.AddMessage('Calculated Boundary')\n",
    "\n",
    "    #   arcpy.env.extent = arcpy.Extent(dem.extent.XMin, dem.extent.YMin, dem.extent.XMax, dem.extent.YMax)\n",
    "    # Convert boundary, i.e., raster line to int for cost allocation function. It only takes int rasters\n",
    "    MULTIPLIER = 10000\n",
    "    boundary_int = Int(boundary * MULTIPLIER)\n",
    "    boundary_int.save(\"boundary_int\")\n",
    "    arcpy.AddMessage('Running cost allocation')\n",
    "    with arcpy.EnvManager(snapRaster=None, extent=\"DEFAULT\", mask=clip_dem):\n",
    "        # cost_alloc = CostAllocation(boundary, cost_raster, '#', '#', 'Value')\n",
    "        cost_alloc = CostAllocation(boundary_int, cost_raster, '#', '#', 'Value')\n",
    "    \n",
    "    # Divide the result from the cost allocation function using the same constant used to create the integer\n",
    "    # representation of the boundary\n",
    "    cost_alloc = Float(cost_alloc) / MULTIPLIER\n",
    "    arcpy.AddMessage('Cost Allocation raster generated')\n",
    "    arcpy.AddMessage('Calculating estimated water depth')\n",
    "    # Raster calculator cost_alloc - clip_dem\n",
    "    water_depth = (cost_alloc - clip_dem_ras)\n",
    "    \n",
    "    # Remove estimated water depths below 0 and change them to 0\n",
    "    #water_depth = Con(water_depth <= 0, 0, water_depth)\n",
    "    water_depth = Con(water_depth > 0, water_depth,\"#\")\n",
    "    water_depth.save(Out_WaterDepth)\n",
    "    arcpy.AddMessage('Floodwater depth computed')\n",
    "    #Run a low-pass filter\n",
    "    arcpy.AddMessage('Running low-pass Filter')\n",
    "    water_depth_filtered = Filter(water_depth, 'LOW', 'DATA')\n",
    "    waterDepthFilter2 = Con(clip_dem_ras, water_depth_filtered, '#', 'VALUE > 0')\n",
    "    waterDepthFilter2.save(Out_WaterDepth+'_filtered')\n",
    "    \n",
    "def CalculateBoundary(dem, clip_dem_ras, inund_polygon, cell_size,numIterations,slopeTH):\n",
    "    \"\"\"\n",
    "    Return a raster line representation with associated underlying DEM values as the values.\n",
    "    Take in a inundated flood polygon, create a polyline representation of the input inundation_polygon.\n",
    "    Next, convert flood polygon polyline calculated in the first step to a raster.\n",
    "    Then, set values of newly created 'raster line' to the underlying dem values.\n",
    "    Finally, save the raster line to the workspace\n",
    "    Much of the naming conventions found in this function follow the arcpy documentation for the 'Con' function.\n",
    "    Input:\n",
    "        dem -> ArcPy raster object\n",
    "        inundation_polygon -> str\n",
    "        cell_size -> int\n",
    "    Return:\n",
    "        str of raster line\n",
    "    \"\"\"\n",
    "    arcpy.AddMessage('Converting inundation polygon to inundation polyline')\n",
    "    # Convert inundation extent polygon to polyline\n",
    "    polyline = 'polyline'\n",
    "    arcpy.PolygonToLine_management(inund_polygon, polyline)\n",
    "    arcpy.AddMessage('Converting inundation polyline to raster')\n",
    "    # Convert polyline to raster\n",
    "    with arcpy.EnvManager(snapRaster=clip_dem_ras):\n",
    "        arcpy.conversion.PolylineToRaster(polyline, 'FID', 'linerast15', \"MAXIMUM_LENGTH\", \"NONE\", cell_size)\n",
    "    raster_polyline = Raster('linerast15')\n",
    "    try:\n",
    "    # Assuming raster_polyline is created somewhere above this\n",
    "        if raster_polyline is not None:\n",
    "            raster_polyline.save(\"polyline.tif\")\n",
    "        else:\n",
    "            print(\"raster_polyline is None or invalid.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the raster polyline: {e}\")\n",
    "    # The input whose values will be used as the output cell values if the condition is false.\n",
    "    inFalseConstant = '#'\n",
    "    where_clause = 'VALUE >= 0'\n",
    "    #Extract the boundary cells elevation from DEM\n",
    "    boundary = Con(raster_polyline, dem, inFalseConstant, where_clause)\n",
    "    # boundary.save('boundary1')\n",
    "    #Smooth boundary raster\n",
    "    iterations = int(numIterations)\n",
    "    for i in range(iterations):\n",
    "        arcpy.AddMessage('Focal iteration '+str(i+1))\n",
    "        OutRasTemp = FocalStatistics(boundary, \"Rectangle 5 5 CELL\", 'MEAN', 'DATA')\n",
    "        boundary = Con(raster_polyline, OutRasTemp, inFalseConstant, where_clause)\n",
    "        boundary.save('boundary'+str(i+1))\n",
    "    #Identify and remove ocean boundary cells\n",
    "    OutRasTemp = FocalStatistics(dem, 'Circle 2 CELL', 'MINIMUM', 'DATA') \n",
    "    whereClause2 = 'VALUE > 0'\n",
    "    boundary = Con(OutRasTemp, boundary, inFalseConstant, whereClause2)\n",
    "    boundary.save(\"boundaryAfterOcean\")\n",
    "    if slopeTH>0.0:\n",
    "    #calculate topo slope\n",
    "        arcpy.AddMessage('Calculating Slope')\n",
    "        extent_clip = '{} {} {} {}'.format(boundary.extent.XMin, boundary.extent.YMin, boundary.extent.XMax, boundary.extent.YMax)\n",
    "        with arcpy.EnvManager(extent=extent_clip):\n",
    "            out_slope = arcpy.sa.Slope(dem, \"PERCENT_RISE\", 1, \"GEODESIC\", \"METER\")\n",
    "            out_slope.save(\"Slope_m\")\n",
    "    #Remove erroneous boundary cells \n",
    "        whereClause_slope = 'VALUE > ' + str(slopeTH)\n",
    "        #boundary = arcpy.sa.Con(out_slope, boundary, None, \"VALUE > 1.0\")\n",
    "        boundary = Con(out_slope, boundary, inFalseConstant, whereClause_slope)\n",
    "  \n",
    "    boundary.save(\"boundFinal\")\n",
    "    # Removing created eronious generated objects\n",
    "   # arcpy.Delete_management(raster_polyline)\n",
    "   # arcpy.Delete_management(polyline)\n",
    "    return boundary\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#clip_dem = '' #[Optional] - If empty, the clip_dem will be calculated with the Clip_management function\n",
    "#cost_raster ='' #[Optional] - If empty, the CostRaster will be calculated below\n",
    "WaterDepthOutput = 'WaterDepth_i10_s0p5'\n",
    "iterations = 10\n",
    "SlopeFiltering = True\n",
    "SlopeThreshold = 0.5\n",
    "inund_polygon = predictions # This is a new addition!! is it correct??? is inund_polgon supposed to be the predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and create necessary variables\n",
    "dem = arcpy.Raster(dem_name)\n",
    "cell_size = dem.meanCellHeight\n",
    "# Proper string representation of dem extent to be accepted by Clip_management method\n",
    "extent = '{} {} {} {}'.format(dem.extent.XMin, dem.extent.YMin, dem.extent.XMax, dem.extent.YMax)\n",
    "\n",
    "# Dont run these if cost_raster and clip_dem are already defined above\n",
    "cost_raster = (((dem <= 0)*999)+1)\n",
    "cost_raster.save('CostRaster.tif')\n",
    "\n",
    "clip_dem = 'ClipDEM'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyn\\AppData\\Local\\Temp\\ipykernel_7140\\2676260078.py:18: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  huc_geom = [huc_gdf.geometry.unary_union.__geo_interface__]\n"
     ]
    }
   ],
   "source": [
    "# clip the DEM to the huc extent\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "\n",
    "# Step 2: Load the HUC shapefile\n",
    "huc_shapefile_path = extent\n",
    "huc_gdf = huc\n",
    "\n",
    "# Step 3: Read the DEM file\n",
    "dem_path = dem_name\n",
    "with rasterio.open(dem_path) as dem_src:\n",
    "    # Step 4: Convert HUC geometry to DEM CRS, if necessary\n",
    "    if huc_gdf.crs != dem_src.crs:\n",
    "        huc_gdf = huc_gdf.to_crs(dem_src.crs)\n",
    "    \n",
    "    # Get the geometry in GeoJSON format\n",
    "    huc_geom = [huc_gdf.geometry.unary_union.__geo_interface__]\n",
    "    \n",
    "    # Step 5: Clip the DEM\n",
    "    out_image, out_transform = mask(dem_src, huc_geom, crop=True)\n",
    "    \n",
    "    # Define metadata for the new file\n",
    "    out_meta = dem_src.meta.copy()\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform})\n",
    "    \n",
    "    # Step 6: Save the clipped DEM\n",
    "    with rasterio.open('clipped_dem.tif', 'w', **out_meta) as out_file: ### ??? edit the clipped_dem.tif to store in the way we want\n",
    "        out_file.write(out_image)\n",
    "\n",
    "### ??? how to make dem from above cell equal the output of this cell??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Object: Error in executing tool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m arcpy\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39moverwriteOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      3\u001b[0m polyline \u001b[38;5;241m=\u001b[39m infolder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/polyline.shp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m arcpy\u001b[38;5;241m.\u001b[39mPolygonToLine_management(inund_polygon, polyline)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Convert polyline to raster\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m arcpy\u001b[38;5;241m.\u001b[39mEnvManager(snapRaster\u001b[38;5;241m=\u001b[39mclip_dem_ras):\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py:4745\u001b[0m, in \u001b[0;36mPolygonToLine\u001b[1;34m(in_features, out_feature_class, neighbor_option)\u001b[0m\n\u001b[0;32m   4743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[0;32m   4744\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 4745\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py:4742\u001b[0m, in \u001b[0;36mPolygonToLine\u001b[1;34m(in_features, out_feature_class, neighbor_option)\u001b[0m\n\u001b[0;32m   4740\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marcpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marcobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marcobjectconversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convertArcObjectToPythonObject\n\u001b[0;32m   4741\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4742\u001b[0m     retval \u001b[38;5;241m=\u001b[39m convertArcObjectToPythonObject(gp\u001b[38;5;241m.\u001b[39mPolygonToLine_management(\u001b[38;5;241m*\u001b[39mgp_fixargs((in_features, out_feature_class, neighbor_option), \u001b[38;5;28;01mTrue\u001b[39;00m)))\n\u001b[0;32m   4743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[0;32m   4744\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py:512\u001b[0m, in \u001b[0;36mGeoprocessor.__getattr__.<locals>.<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    510\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp, attr)\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(val):\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: val(\u001b[38;5;241m*\u001b[39mgp_fixargs(args, \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convertArcObjectToPythonObject(val)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Object: Error in executing tool"
     ]
    }
   ],
   "source": [
    "# Calculate Boundary Raster\n",
    "arcpy.env.overwriteOutput = True\n",
    "polyline = infolder + '/polyline.shp'\n",
    "arcpy.PolygonToLine_management(inund_polygon, polyline)\n",
    "# Convert polyline to raster\n",
    "with arcpy.EnvManager(snapRaster=clip_dem_ras):\n",
    "    arcpy.conversion.PolylineToRaster(polyline, 'FID', 'linerast15', \"MAXIMUM_LENGTH\", \"NONE\", cell_size)\n",
    "raster_polyline = arcpy.Raster('linerast15')\n",
    "raster_polyline.save(\"rstr_poly\")\n",
    "# The input whose values will be used as the output cell values if the condition is false.\n",
    "inFalseConstant = '#'\n",
    "where_clause = 'VALUE >= 0'\n",
    "#Extract the boundary cells elevation from DEM\n",
    "boundary = arcpy.sa.Con(raster_polyline, dem, inFalseConstant, where_clause)\n",
    "# boundary.save('boundary1')\n",
    "#Smooth boundary raster\n",
    "for i in range(iterations):\n",
    "    OutRasTemp = arcpy.sa.FocalStatistics(boundary, \"Rectangle 5 5 CELL\", 'MEAN', 'DATA')\n",
    "    boundary = arcpy.sa.Con(raster_polyline, OutRasTemp, inFalseConstant, where_clause)\n",
    "    boundary.save('boundary'+str(i+1))\n",
    "#Identify and remove ocean boundary cells\n",
    "OutRasTemp = arcpy.sa.FocalStatistics(dem, 'Circle 2 CELL', 'MINIMUM', 'DATA') \n",
    "whereClause2 = 'VALUE > 0'\n",
    "boundary = arcpy.sa.Con(OutRasTemp, boundary, inFalseConstant, whereClause2)\n",
    "#boundary.save(\"boundaryAfterOcean\")\n",
    "if SlopeFiltering:\n",
    "#calculate topo slope\n",
    "    print('Calculating Slope')\n",
    "    extent_clip = '{} {} {} {}'.format(boundary.extent.XMin, boundary.extent.YMin, boundary.extent.XMax, boundary.extent.YMax)\n",
    "    with arcpy.EnvManager(extent=extent_clip):\n",
    "        out_slope = arcpy.sa.Slope(dem, \"PERCENT_RISE\", 1, \"GEODESIC\", \"METER\")\n",
    "        out_slope.save(\"Slope_m\")\n",
    "#Remove erroneous boundary cells \n",
    "    whereClause_slope = 'VALUE > ' + str(SlopeThreshold)\n",
    "    boundary = arcpy.sa.Con(out_slope, boundary, inFalseConstant, whereClause_slope)\n",
    "boundary.save(\"boundFinal\")\n",
    "print('Finished calculating the boundary raster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate water depth \n",
    "\n",
    "MULTIPLIER = 10000\n",
    "boundary_int = arcpy.sa.Int(boundary * MULTIPLIER)\n",
    "#boundary_int.save(\"boundary_int\")\n",
    "print('Running cost allocation')\n",
    "with arcpy.EnvManager(snapRaster=None, extent=\"DEFAULT\", mask=clip_dem):\n",
    "    cost_alloc = arcpy.sa.CostAllocation(boundary_int, cost_raster, '#', '#', 'Value')\n",
    "\n",
    "# Divide the result from the cost allocation function using the same constant used to create the integer\n",
    "# representation of the boundary\n",
    "cost_alloc = arcpy.sa.Float(cost_alloc) / MULTIPLIER\n",
    "print('Cost Allocation raster generated')\n",
    "print('Calculating estimated water depth')\n",
    "water_depth = (cost_alloc - clip_dem_ras)\n",
    "# Remove estimated water depths below 0 and change them to 0\n",
    "water_depth = arcpy.sa.Con(water_depth > 0, water_depth,\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a low-pass filter\n",
    "# ie smooth the water depth raster\n",
    "print('Running low-pass Filter')\n",
    "water_depth_filtered = arcpy.sa.Filter(water_depth, 'LOW', 'DATA')\n",
    "waterDepthFilter2 = arcpy.sa.Con(clip_dem_ras, water_depth_filtered, '#', 'VALUE > 0')\n",
    "#waterDepthFilter2.save(WaterDepthOutput+'_filtered')\n",
    "print('Finished low-pass Filter calculation')\n",
    "waterDepthFilter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the waterdepth as a tif file\n",
    "# Set the output file path\n",
    "waterdepth_path = infolder + 'waterDepth.tif'\n",
    "\n",
    "# Export the waterDepthFilter2 raster as a TIFF file\n",
    "waterDepthFilter2.save(waterdepth_path)\n",
    "\n",
    "# Print the output file path\n",
    "print(f\"Water depth filter exported as: {waterdepth_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SVI using depth map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load the ESRI Geodatabase and Clip the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.colorbar as colorbar\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.plot import show\n",
    "import folium\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from matplotlib.colors import Normalize\n",
    "from rasterio.transform import from_bounds\n",
    "from osgeo import gdal, ogr, osr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caculate the Impact "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: read the svi raster and fim raster\n",
    "If you have not have an svi map yet, you need to run through Flood Impact Map.ipynb workflow to produce one. Use the output of that here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# Define the paths to the raster files - same as the output above\n",
    "svi_raster_path = svi\n",
    "fim_raster_path = waterdepth_path\n",
    "\n",
    "def check_raster_properties(raster_path):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        print(f\"Properties of {raster_path}:\")\n",
    "        print(f\" CRS: {src.crs}\")\n",
    "        print(f\" Cell size: {src.res}\")\n",
    "        print(f\" Width: {src.width}, Height: {src.height}\")\n",
    "        print(f\" Bounds: {src.bounds}\")\n",
    "        print()\n",
    "\n",
    "# Read and check properties of SVI raster\n",
    "check_raster_properties(svi_raster_path)\n",
    "\n",
    "# Read and check properties of FIM raster\n",
    "check_raster_properties(fim_raster_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Reproject and Resample SVI Raster\n",
    "Skip this if they have same projection and cell size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### make sure that the svi map has the same crs and cell size of fim map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "\n",
    "# Define the paths to the raster files\n",
    "aligned_svi_raster_path = infolder + 'aligned_svi_raster2.tif'\n",
    "\n",
    "# Open the FIM raster to get the projection, geotransform, and size\n",
    "fim_ds = gdal.Open(fim_raster_path)\n",
    "if fim_ds is None:\n",
    "    raise RuntimeError(f\"Failed to open FIM raster {fim_raster_path}\")\n",
    "\n",
    "fim_proj = fim_ds.GetProjection()\n",
    "fim_geotransform = fim_ds.GetGeoTransform()\n",
    "fim_width = fim_ds.RasterXSize\n",
    "fim_height = fim_ds.RasterYSize\n",
    "\n",
    "print(f\"FIM Raster Properties:\\n CRS: {fim_proj}\\n Geotransform: {fim_geotransform}\\n Width: {fim_width}, Height: {fim_height}\")\n",
    "\n",
    "# Reproject and resample the SVI raster to match the FIM raster\n",
    "warp_options = gdal.WarpOptions(\n",
    "    format='GTiff',\n",
    "    outputBounds=(fim_geotransform[0], fim_geotransform[3] + fim_height * fim_geotransform[5], fim_geotransform[0] + fim_width * fim_geotransform[1], fim_geotransform[3]),\n",
    "    width=fim_width,\n",
    "    height=fim_height,\n",
    "    dstSRS=fim_proj,\n",
    "    xRes=fim_geotransform[1],\n",
    "    yRes=-fim_geotransform[5],\n",
    "    resampleAlg=gdal.GRA_Bilinear,\n",
    "    targetAlignedPixels=True\n",
    ")\n",
    "\n",
    "print(\"Warp options set.\")\n",
    "\n",
    "aligned_svi_raster = gdal.Warp(aligned_svi_raster_path, svi_raster_path, options=warp_options)\n",
    "if aligned_svi_raster is None:\n",
    "    raise RuntimeError(f\"gdal.Warp failed to create {aligned_svi_raster_path}\")\n",
    "\n",
    "print(\"SVI raster has been reprojected and resampled to match the FIM raster.\")\n",
    "\n",
    "# Verify the properties of the aligned SVI raster\n",
    "def check_raster_properties(raster_path):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        print(f\"Properties of {raster_path}:\")\n",
    "        print(f\" CRS: {src.crs}\")\n",
    "        print(f\" Cell size: {src.res}\")\n",
    "        print(f\" Width: {src.width}, Height: {src.height}\")\n",
    "        print(f\" Bounds: {src.bounds}\")\n",
    "        print()\n",
    "\n",
    "# Check properties of the aligned SVI raster\n",
    "check_raster_properties(aligned_svi_raster_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reclassify fim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def reclassify_fim(input_path, output_path):\n",
    "    with rasterio.open(input_path) as src:\n",
    "        data = src.read(1).astype('float32')\n",
    "        nodata = src.nodata\n",
    "\n",
    "        if nodata is not None:\n",
    "            data = np.ma.masked_equal(data, nodata)\n",
    "        \n",
    "        # Reclassify the FIM data\n",
    "        reclassified_data = np.digitize(data, bins=[0.01, 0.5, 1, 2], right=True)\n",
    "        reclassified_data = np.where(data == 0, 0, reclassified_data)  # Class 0 for non-flooded areas\n",
    "\n",
    "        # Preserve nodata values\n",
    "        reclassified_data = np.ma.filled(reclassified_data, nodata)\n",
    "\n",
    "        meta = src.meta\n",
    "        meta.update(dtype='float32', nodata=-9999)\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "            dst.write(reclassified_data.astype('float32'), 1)\n",
    "\n",
    "\n",
    "reclassified_fim_path = infolder + 'aligned_fim.tif'\n",
    "\n",
    "reclassify_fim(fim_raster_path, reclassified_fim_path)\n",
    "print(\"Reclassified FIM raster has been saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create impact map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_rasters(svi_path, fim_path, output_path):\n",
    "    with rasterio.open(svi_path) as svi_src:\n",
    "        svi_data = svi_src.read(1).astype('float32')\n",
    "        svi_nodata = svi_src.nodata\n",
    "\n",
    "    with rasterio.open(fim_path) as fim_src:\n",
    "        fim_data = fim_src.read(1).astype('float32')\n",
    "        fim_meta = fim_src.meta\n",
    "        fim_nodata = fim_src.nodata\n",
    "\n",
    "    if svi_data.shape != fim_data.shape:\n",
    "        raise ValueError(\"The rasters do not have the same shape.\")\n",
    "\n",
    "    # Ensure that nodata values are handled correctly\n",
    "    nodata_value = -9999\n",
    "    svi_data = np.where(svi_data == svi_nodata, np.nan, svi_data)\n",
    "    fim_data = np.where(fim_data == fim_nodata, np.nan, fim_data)\n",
    "\n",
    "    # Multiply the rasters to get the impact map, ignoring NaN values\n",
    "    impact_data = np.where(np.isnan(svi_data) | np.isnan(fim_data), nodata_value, svi_data * fim_data)\n",
    "\n",
    "    # Save the impact map to a new raster file\n",
    "    impact_meta = fim_meta.copy()\n",
    "    impact_meta.update({\n",
    "        'dtype': 'float32',\n",
    "        'nodata': nodata_value\n",
    "    })\n",
    "\n",
    "    with rasterio.open(output_path, 'w', **impact_meta) as impact_dst:\n",
    "        impact_dst.write(impact_data.astype('float32'), 1)\n",
    "\n",
    "svi_raster_path = svi\n",
    "impact_raster_path = infolder + 'impact_raster.tif'\n",
    "\n",
    "multiply_rasters(svi_raster_path, reclassified_fim_path, impact_raster_path)\n",
    "print(\"Impact map has been saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask 0s in the impact map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def mask_zeros(input_path, output_path):\n",
    "    with rasterio.open(input_path) as src:\n",
    "        data = src.read(1).astype('float32')\n",
    "        nodata = src.nodata\n",
    "\n",
    "        masked_data = np.where(data == 0, nodata, data)\n",
    "\n",
    "        meta = src.meta\n",
    "        meta.update(dtype='float32', nodata=nodata)\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "            dst.write(masked_data.astype('float32'), 1)\n",
    "\n",
    "\n",
    "masked_impact_raster_path = infolder + 'masked_impact_raster.tif'\n",
    "\n",
    "mask_zeros(impact_raster_path, masked_impact_raster_path)\n",
    "print(\"Masked impact map has been saved.\")\n",
    "\n",
    "def plot_raster(ax, raster_path, title):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        data = src.read(1)\n",
    "        nodata = src.nodata\n",
    "        if nodata is not None:\n",
    "            data = np.ma.masked_equal(data, nodata)  # Mask NoData values\n",
    "\n",
    "        img = ax.imshow(data, cmap='plasma', norm=Normalize(vmin=data.min(), vmax=data.max()))\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        return img\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the masked impact raster\n",
    "img = plot_raster(ax, masked_impact_raster_path, \"Masked Impact Raster\")\n",
    "\n",
    "# Add colorbars with size control\n",
    "cbar = fig.colorbar(img, ax=ax, fraction=0.046, pad=0.04, shrink=0.4)\n",
    "cbar.set_label('Impact Value')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reclassify the impact map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def classify_raster(input_path, output_path):\n",
    "    with rasterio.open(input_path) as src:\n",
    "        data = src.read(1).astype('float32')\n",
    "        nodata = src.nodata\n",
    "\n",
    "        # Mask nodata values\n",
    "        data_masked = np.ma.masked_equal(data, nodata)\n",
    "        \n",
    "        # Identify the range of the data excluding nodata values\n",
    "        min_value = data_masked.min()\n",
    "        max_value = data_masked.max()\n",
    "        print(f\"Data range: {min_value} to {max_value}\")\n",
    "\n",
    "        # Classify the data into 4 equal intervals\n",
    "        bins = np.linspace(min_value, max_value, 5)  # 5 bins will create 4 intervals\n",
    "        classified_data = np.digitize(data_masked, bins, right=True)  # Digitize creates 1 to 4 classes\n",
    "\n",
    "        # Convert the classified_data mask to nodata values\n",
    "        classified_data[data_masked.mask] = nodata\n",
    "\n",
    "        print(f\"Classified data range: {np.min(classified_data)} to {np.max(classified_data)}\")\n",
    "\n",
    "        meta = src.meta\n",
    "        meta.update(dtype='float32', nodata=nodata)\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "            dst.write(classified_data.astype('float32'), 1)\n",
    "\n",
    "\n",
    "classified_impact_raster_path = infolder + 'classified_impact_raster.tif'\n",
    "\n",
    "classify_raster(masked_impact_raster_path, classified_impact_raster_path)\n",
    "print(\"Classified impact map has been saved.\")\n",
    "\n",
    "def plot_raster(ax, raster_path, title):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        data = src.read(1)\n",
    "        nodata = src.nodata\n",
    "        if nodata is not None:\n",
    "            data = np.ma.masked_equal(data, nodata)  # Mask NoData values\n",
    "\n",
    "        img = ax.imshow(data, cmap='plasma', norm=Normalize(vmin=1, vmax=4))  # Set vmin and vmax to match class values\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        return img\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the classified impact raster\n",
    "img = plot_raster(ax, classified_impact_raster_path, \"Classified Impact Raster\")\n",
    "\n",
    "# Add colorbars with size control\n",
    "cbar = fig.colorbar(img, ax=ax, fraction=0.046, pad=0.04, shrink=0.4)\n",
    "cbar.set_label('Impact Class')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def raster_to_shapefile(raster_path, shapefile_path):\n",
    "    # Open the reclassified raster\n",
    "    src_ds = gdal.Open(raster_path)\n",
    "    if src_ds is None:\n",
    "        raise RuntimeError(f\"Failed to open raster {raster_path}\")\n",
    "    \n",
    "    # Get the raster band\n",
    "    src_band = src_ds.GetRasterBand(1)\n",
    "    nodata = src_band.GetNoDataValue()\n",
    "    \n",
    "    # Create the output shapefile\n",
    "    driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "    if driver is None:\n",
    "        raise RuntimeError(\"ESRI Shapefile driver not available.\")\n",
    "    \n",
    "    dst_ds = driver.CreateDataSource(shapefile_path)\n",
    "    if dst_ds is None:\n",
    "        raise RuntimeError(f\"Failed to create shapefile {shapefile_path}\")\n",
    "    \n",
    "    srs = ogr.osr.SpatialReference()\n",
    "    srs.ImportFromWkt(src_ds.GetProjection())\n",
    "    \n",
    "    dst_layer = dst_ds.CreateLayer('impact', srs=srs, geom_type=ogr.wkbPolygon)\n",
    "    if dst_layer is None:\n",
    "        raise RuntimeError(f\"Failed to create layer in shapefile {shapefile_path}\")\n",
    "    \n",
    "    field_defn = ogr.FieldDefn('FIV_Class', ogr.OFTInteger)\n",
    "    dst_layer.CreateField(field_defn)\n",
    "    \n",
    "    # Polygonize the raster, skipping NoData values\n",
    "    gdal.Polygonize(src_band, src_band.GetMaskBand(), dst_layer, 0, options=[\"8CONNECTED=8\"], callback=None)\n",
    "    \n",
    "    # Remove features with the NoData value\n",
    "    dst_layer.SetAttributeFilter(f\"FIV_Class = {int(nodata)}\")\n",
    "    for feature in dst_layer:\n",
    "        dst_layer.DeleteFeature(feature.GetFID())\n",
    "    dst_layer.SetAttributeFilter(None)\n",
    "    \n",
    "    # Close the datasets\n",
    "    src_ds = None\n",
    "    dst_ds = None\n",
    "\n",
    "# Path to the reclassified impact raster file\n",
    "reclassified_raster_path = classified_impact_raster_path\n",
    "shapefile_path = infolder + 'reclassified_impact_raster.shp'\n",
    "\n",
    "\n",
    "# Convert the reclassified raster to a shapefile\n",
    "raster_to_shapefile(reclassified_raster_path, shapefile_path)\n",
    "print(\"Shapefile has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add column to attribute table of FIV map to describe the severity of the vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import ogr\n",
    "\n",
    "def add_vulnerability_column(shapefile_path):\n",
    "    # Open the shapefile\n",
    "    driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "    ds = driver.Open(shapefile_path, 1)  # Open in write mode\n",
    "    if ds is None:\n",
    "        raise RuntimeError(f\"Failed to open shapefile {shapefile_path}\")\n",
    "    \n",
    "    layer = ds.GetLayer()\n",
    "    \n",
    "    # Add new field for vulnerability levels\n",
    "    vulnerability_field = ogr.FieldDefn('Vuln_Level', ogr.OFTString)\n",
    "    vulnerability_field.SetWidth(32)\n",
    "    layer.CreateField(vulnerability_field)\n",
    "    \n",
    "    # Define the vulnerability levels\n",
    "    vulnerability_levels = {\n",
    "        1: \"Low Vulnerability\",\n",
    "        2: \"Medium Vulnerability\",\n",
    "        3: \"High Vulnerability\",\n",
    "        4: \"Very High Vulnerability\"    \n",
    "    }\n",
    "    \n",
    "    # Update the new field based on FIV_Class\n",
    "    for feature in layer:\n",
    "        fiv_class = feature.GetField('FIV_Class')\n",
    "        vulnerability_level = vulnerability_levels.get(fiv_class, \"Unknown\")\n",
    "        feature.SetField('Vuln_Level', vulnerability_level)\n",
    "        layer.SetFeature(feature)\n",
    "    \n",
    "    # Close the dataset\n",
    "    ds = None\n",
    "    print(\"Vulnerability level column has been added to the shapefile.\")\n",
    "\n",
    "# Path to the shapefile\n",
    "shapefile_path = infolder+'ImpactMap.shp'\n",
    "\n",
    "# Add the vulnerability level column\n",
    "add_vulnerability_column(shapefile_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export outputs to ArcGIS online\n",
    "\n",
    "This is the notebook to update the arcgis instant app\n",
    "This requires arcpy as a package\n",
    "Before running this notebook, you should have already set up the acrGIS instant app. This notebook only replaces the shapefile already in the map, it does not create a new map. You need to do that first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster to Shapefile conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raster to shapefile conversion\n",
    "\n",
    "from osgeo import gdal, ogr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def raster_to_shapefile(raster_path, shapefile_path):\n",
    "    # Open the reclassified raster\n",
    "    src_ds = gdal.Open(raster_path)\n",
    "    if src_ds is None:\n",
    "        raise RuntimeError(f\"Failed to open raster {raster_path}\")\n",
    "    \n",
    "    # Get the raster band\n",
    "    src_band = src_ds.GetRasterBand(1)\n",
    "    nodata = src_band.GetNoDataValue()\n",
    "    \n",
    "    # Create the output shapefile\n",
    "    driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "    if driver is None:\n",
    "        raise RuntimeError(\"ESRI Shapefile driver not available.\")\n",
    "    \n",
    "    dst_ds = driver.CreateDataSource(shapefile_path)\n",
    "    if dst_ds is None:\n",
    "        raise RuntimeError(f\"Failed to create shapefile {shapefile_path}\")\n",
    "    \n",
    "    srs = ogr.osr.SpatialReference()\n",
    "    srs.ImportFromWkt(src_ds.GetProjection())\n",
    "    \n",
    "    dst_layer = dst_ds.CreateLayer('impact', srs=srs, geom_type=ogr.wkbPolygon)\n",
    "    if dst_layer is None:\n",
    "        raise RuntimeError(f\"Failed to create layer in shapefile {shapefile_path}\")\n",
    "    \n",
    "    field_defn = ogr.FieldDefn('FIV_Class', ogr.OFTInteger)\n",
    "    dst_layer.CreateField(field_defn)\n",
    "    \n",
    "    # Polygonize the raster, skipping NoData values\n",
    "    gdal.Polygonize(src_band, src_band.GetMaskBand(), dst_layer, 0, options=[\"8CONNECTED=8\"], callback=None)\n",
    "    \n",
    "    # Remove features with the NoData value\n",
    "    dst_layer.SetAttributeFilter(f\"FIV_Class = {int(nodata)}\")\n",
    "    for feature in dst_layer:\n",
    "        dst_layer.DeleteFeature(feature.GetFID())\n",
    "    dst_layer.SetAttributeFilter(None)\n",
    "    \n",
    "    # Close the datasets\n",
    "    src_ds = None\n",
    "    dst_ds = None\n",
    "\n",
    "# Path to the reclassified impact raster file\n",
    "reclassified_raster_path = 'F:/SI_2024/Final__inputs_outputs/Final__inputs_outputs/Original_reclassified_Depths_fwdet/reclassified_fwdet_Beryl_18hr_08Jul_08_10_nonad.tif'\n",
    "\n",
    "# the output needs to be in its own folder\n",
    "# Define the path for the new folder\n",
    "shapefile_path = 'F:/SI_2024/Final__inputs_outputs/Final__inputs_outputs/18hr_depth_shapefile/depthmap'\n",
    "# Create the new folder\n",
    "os.makedirs(shapefile_path, exist_ok=True)\n",
    "print(f\"New folder created at: {shapefile_path}\")\n",
    "\n",
    "# Convert the reclassified raster to a shapefile\n",
    "raster_to_shapefile(reclassified_raster_path, shapefile_path)\n",
    "print(\"Shapefile has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zip the shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the shapefile\n",
    "import shutil\n",
    "shapefile_name = 'reclassified_depth.shp'\n",
    "\n",
    "# Create a zip file of the source folder\n",
    "shutil.make_archive(shapefile_name, 'zip', shapefile_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the GIS object, we pass your profile that contains the url and your login credentials. Please replace the credentials below with that of your org. \n",
    "To learn more about profiles, see [here](https://developers.arcgis.com/python/guide/working-with-different-authentication-schemes/#Storing-your-credentialls-locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS('home')\n",
    "\n",
    "\n",
    "#If this does not automatically connect, you may need to do this code instead:\n",
    "#gis = GIS(\n",
    "#  url=\"https://www.arcgis.com\",\n",
    "#  username=\"username\",\n",
    "#  password=getpass.getpass(\"Enter password:\")\n",
    "#)\n",
    "\n",
    "# or do this:\n",
    "# gis = GIS(\"https://www.arcgis.com\", \"your_username\", \"your_password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the former shapefile so we can upload the new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for the layer id\n",
    "search_result = gis.content.search('title:FIM', item_type = 'Feature Service')\n",
    "display(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'item_id' with the actual ID of the item you want to delete\n",
    "item_id = search_result[0].id\n",
    "item_to_delete = gis.content.get(item_id)\n",
    "\n",
    "# Delete the item, remove it permanently is necesary if you have a recycle bin enabled at your organization\n",
    "item_to_delete.delete(permanent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for the shapefile ID\n",
    "search_result = gis.content.search('title:FIM', item_type = 'Shapefile')\n",
    "display(search_result)\n",
    "\n",
    "# Replace 'item_id' with the actual ID of the item you want to delete\n",
    "item_id = search_result[0].id\n",
    "item_to_delete = gis.content.get(item_id)\n",
    "\n",
    "# Delete the item, remove it permanently is necesary if you have a recycle bin enabled at your organization\n",
    "item_to_delete.delete(permanent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upload the new shapefile to ArcGIS Online\n",
    "edit the metadata with the title and tags of the file. the path must lead to a zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datetime to tag the file name\n",
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "print(current_datetime)\n",
    "\n",
    "# Format the datetime as a string (e.g., \"2023-04-01 12:00\")\n",
    "formatted_datetime = current_datetime.strftime('%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the dictionary with the title and tags you want\n",
    "metadata = {\n",
    "    'title': f'FIM {formatted_datetime}',\n",
    "    'tags': 'Flood Forecast, 5 Days, Inundation, National Water Model',\n",
    "    'type': 'Shapefile'\n",
    "}\n",
    "data_path = os.path.join('C:/Users/Lyn/Desktop/Berylb.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = gis.content.add(metadata, data=data_path)\n",
    "feature_layer = shapefile.publish()\n",
    "feature_layer.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Add the layer to the webmap Instant App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.mapping import WebMap, WebScene\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "\n",
    "# ID the web map you want to alter\n",
    "search_result = gis.content.search(\"title:Flood Forecast Houston\", item_type = \"Web Map\")\n",
    "\n",
    "# read the webmap as an object\n",
    "wm_item = search_result[0]\n",
    "web_map_obj = WebMap(wm_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the layers on the web map\n",
    "for lyr in web_map_obj.layers:\n",
    "    print(lyr.title + \" \" + lyr.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature service item id for the missing layer:\n",
    "web_map_obj.layers[0][\"itemId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do : edit the title to match the one above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search for the newly uploaded layer\n",
    "search_result = gis.content.search('title:Berylb', item_type = 'Feature Service')\n",
    "display(search_result)\n",
    "\n",
    "# check the item id\n",
    "search_result[0].id\n",
    "\n",
    "# update the web map with the new layer\n",
    "capitals = search_result[0]\n",
    "capitals.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new feature service does have a layer with id 0. Hence we can use the same layer id while switching the url. \n",
    "# To remove the old layer, call remove_layer() method. \n",
    "# Then add the correct FeatureLayer object by calling the add_layer() method on the WebMap object.\n",
    "\n",
    "# remove the old layer from the web map\n",
    "web_map_obj.remove_layer(web_map_obj.layers[0])\n",
    "\n",
    "# add the correct layer. While adding you can customize the title\n",
    "web_map_obj.add_layer(capitals.layers[0], options={'title':'Berylb'})\n",
    "\n",
    "#check the layers on the web map\n",
    "for lyr in web_map_obj.layers:\n",
    "    print(lyr.title + \" \" + lyr.url)\n",
    "\n",
    "# update the web map \n",
    "web_map_obj.update(item_properties={'title':'USA Capitals - updated'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do: Make sure what you delete matches the variable names above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clean it up so we can always run this section again\n",
    "wm_item.delete()\n",
    "#new_capitals.delete()\n",
    "#csv_item.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
